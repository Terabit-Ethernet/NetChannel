#!/usr/bin/python3

# Copyright (c) 2019-2020, Stanford University
#
# Permission to use, copy, modify, and/or distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

# This program runs one or more performance measurements of Homa on
# a cluster of machines with names "node-0" to "node-N". Type
# "cperf --help" for elementary documentation.
# Usage:
# cperf [options] test test ...

import argparse
import fcntl
import glob
import os
import re
import shutil
import subprocess
import sys
import time
import traceback

# Each entry in this array contains the Popen object for communication
# with one node (indexed by node number).
nodes = []

# Names of nodes that did not exit normally.
fail_nodes = []

# Open file for log messages to be retained in the log directory.
log_file = 0

def log(message):
    """
    Write the message argument both to stdout and to the cperf log file.
    """
    global log_file
    print(message)
    log_file.write(message)
    log_file.write("\n")

def wait_output(string, r, cmd):
    """
    The r argument specifies a range of node indexes. This method waits
    until the given string has appeared on the stdout of each of the given
    nodes. If a long time goes by without the string appearing, an exception
    is thrown; the cmd argument is used in the error message to indicate
    the command that failed.
    """
    global nodes
    outputs = []
    printed = False

    for i in r:
        while len(outputs) <= i:
            outputs.append("")
    start_time = time.time()
    while time.time() < (start_time + 5.0):
        for i in r:
            data = nodes[i].stdout.read(1000)
            if data != None:
                print_data = data
                if print_data.endswith(string):
                    print_data = print_data[:(len(data) - len(string))]
                if print_data != "":
                    log("output from node-%d: '%s'" % (i, print_data))
                outputs[i] += data
        bad_node = -1
        for i in r:
            if not string in outputs[i]:
                bad_node = i
                break
        if bad_node < 0:
            return
        if (time.time() > (start_time + 5.0)) and not printed:
            log("expected output from node-%d not yet received "
            "after command '%s': expecting '%s', got '%s'"
            % (bad_node, cmd, string, outputs[bad_node]))
            printed = True;
        time.sleep(0.1)
    raise Exception("bad output from node-%d after command '%s': "
            "expected '%s', got '%s'"
            % (bad_node, cmd, string, outputs[bad_node]))

def start_nodes(r):
    """
    Start up cp_node on the given range of node indexes. References
    to the nodes will be stored in the nodes array.
    """
    global nodes, args
    while len(nodes) < r.stop:
        nodes.append(None)
    for n in r:
        node = subprocess.Popen(["ssh", "-o", "StrictHostKeyChecking=no",
                "node-%d" % (n), "cp_node"], encoding="utf-8",
                stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT)
        fl = fcntl.fcntl(node.stdin, fcntl.F_GETFL)
        fcntl.fcntl(node.stdin, fcntl.F_SETFL, fl | os.O_NONBLOCK)
        fl = fcntl.fcntl(node.stdout, fcntl.F_GETFL)
        fcntl.fcntl(node.stdout, fcntl.F_SETFL, fl | os.O_NONBLOCK)
        nodes[n] = node
    wait_output("% ", r, "ssh")
    if (args.debug):
            log('Servers started; pausing for debug setup.')
            input('Type <Enter> to continue: ')

def stop_nodes():
    """
    Exit all of the nodes that are currently running.
    """
    global nodes
    for n in nodes:
        n.stdin.write("exit\n")
        n.stdin.flush()
    for n in nodes:
        n.wait(5.0)   

def do_cmd(command, r):
    """
    Execute a cp_node command on the range of notes given by r, and
    wait for the command to complete on each node. The command should
    be terminated by a newline.
    """
    global nodes
    for n in r:
        nodes[n].stdin.write(command)
        nodes[n].stdin.flush()
    wait_output("% ", r, command)

def scan_log(file, node, data):
    """
    Read a single log file and extract various useful information,
    such as fatal error messages or interesting statistics. The node
    parameter gives the name of the node that generated the log. The
    data argument is an object that will be filled in with info
    extracted from the log; see scan_logs for details.
    """
    exited = False
    prot = ""

    for line in open(file):
        if "Starting loaded experiment" in line:
            prot = "homa"
        if "Starting TCP experiment" in line:
            prot = "tcp"
        if "Command: dump_times" in line:
            prot = ""
        if prot != "":
            match = re.match('.*(Clients|Servers): ([0-9.]+) Kops/sec, '
                        '([0-9.]+) MB/sec', line)
            if match:
                if match.group(1) == "Clients":
                    type = "client"
                else:
                    type = "server"
                key = type + "_" + prot + "_kops"
                if not node in data[key]:
                    data[key][node] = []
                data[key][node].append(float(match.group(2)))
                key = type + "_" + prot + "_bw"
                if not node in data[key]:
                    data[key][node] = []
                data[key][node].append(float(match.group(3)))
        if "FATAL:" in line:
            log("%s: %s" % (file, line))
            exited = True
        if "cp_node exiting" in line:
            exited = True
    if not exited:
        data["fail_nodes"].append(node)

def scan_logs():
    """
    Read all of the nodte-specific log files produced by a run, and
    extract useful information.
    """
    data = {}

    # Names of nodes that didn't exit normally.
    data["fail_nodes"] = []

    # Dictionaries indexed by node names; each value is a list of
    # measured throughputs (for client or server, Homa or TCP) for
    # that node (each reading is one second during the experiment).
    data["client_homa_bw"] = {}
    data["server_homa_bw"] = {}
    data["client_tcp_bw"] = {}
    data["server_tcp_bw"] = {}

    # Same as above, but measuring kops/sec. instead of throughput.
    data["client_homa_kops"] = {}
    data["server_homa_kops"] = {}
    data["client_tcp_kops"] = {}
    data["server_tcp_kops"] = {}

    for file in sorted(glob.glob(args.log_dir + "/node-*.log")):
        node = re.match('.*/(node-[0-9]+)\.log', file).group(1)
        scan_log(file, node, data)

    client_avg_kops = server_avg_kops = client_avg_bw = server_avg_bw = 0.0
    averages = []
    log("Homa clients")
    log("------------")
    for node in sorted(data["client_homa_bw"].keys()):
        bw = data["client_homa_bw"][node]
        avg = sum(bw)/len(bw)
        log("%s: %.1f MB/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), bw))))
        averages.append(avg)
    if len(averages) > 0:
        client_avg_bw = sum(averages)/len(averages)
        log("Overall average: %.1f MB/sec\n" % (client_avg_bw))

    averages = []
    for node in sorted(data["client_homa_kops"].keys()):
        kops = data["client_homa_kops"][node]
        avg = sum(kops)/len(kops)
        log("%s: %.1f Kops/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), kops))))
        averages.append(avg)
    if len(averages) > 0:
        client_avg_kops = sum(averages)/len(averages)
        log("Overall average: %.1f Kops/sec\n" % (client_avg_kops))

    averages = []
    log("Homa servers")
    log("------------")
    for node in sorted(data["server_homa_bw"].keys()):
        bw = data["server_homa_bw"][node]
        avg = sum(bw)/len(bw)
        log("%s: %.1f MB/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), bw))))
        averages.append(avg)
    if len(averages) > 0:
        server_avg_bw = sum(averages)/len(averages)
        log("Overall average: %.1f MB/sec\n" % (client_avg_bw))

    averages = []
    for node in sorted(data["server_homa_kops"].keys()):
        kops = data["server_homa_kops"][node]
        avg = sum(kops)/len(kops)
        log("%s: %.1f Kops/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), kops))))
        averages.append(avg)
    if len(averages) > 0:
        server_avg_kops = sum(averages)/len(averages)
        log("Overall average: %.1f Kops/sec" % (client_avg_kops))
    log("Homa totals: %.1f Kops/sec, %.1f MB/sec\n" % (
            client_avg_kops + server_avg_kops, client_avg_bw + server_avg_bw))

    client_avg_kops = server_avg_kops = client_avg_bw = server_avg_bw = 0.0
    averages = []
    log("TCP clients")
    log("------------")
    for node in sorted(data["client_tcp_bw"].keys()):
        bw = data["client_tcp_bw"][node]
        avg = sum(bw)/len(bw)
        log("%s: %.1f MB/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), bw))))
        averages.append(avg)
    if len(averages) > 0:
        client_avg_bw = sum(averages)/len(averages)
        log("Overall average: %.1f MB/sec\n" % (client_avg_bw))

    averages = []
    for node in sorted(data["client_tcp_kops"].keys()):
        kops = data["client_tcp_kops"][node]
        avg = sum(kops)/len(kops)
        log("%s: %.1f Kops/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), kops))))
        averages.append(avg)
    if len(averages) > 0:
        client_avg_kops = sum(averages)/len(averages)
        log("Overall average: %.1f Kops/sec\n" % (client_avg_kops))

    averages = []
    log("TCP servers")
    log("------------")
    for node in sorted(data["server_tcp_bw"].keys()):
        bw = data["server_tcp_bw"][node]
        avg = sum(bw)/len(bw)
        log("%s: %.1f MB/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), bw))))
        averages.append(avg)
    if len(averages) > 0:
        server_avg_bw = sum(averages)/len(averages)
        log("Overall average: %.1f MB/sec\n" % (client_avg_bw))

    averages = []
    for node in sorted(data["server_tcp_kops"].keys()):
        kops = data["server_tcp_kops"][node]
        avg = sum(kops)/len(kops)
        log("%s: %.1f Kops/sec (%s)" % (node, avg,
            ", ".join(map(lambda x: "%.1f" % (x), kops))))
        averages.append(avg)
    if len(averages) > 0:
        server_avg_kops = sum(averages)/len(averages)
        log("Overall average: %.1f Kops/sec" % (client_avg_kops))
    log("TCP totals: %.1f Kops/sec, %.1f MB/sec\n" % (
            client_avg_kops + server_avg_kops, client_avg_bw + server_avg_bw))

    if len(data["fail_nodes"]) != 0:
        log("Nodes appear to have crashed: %s" % (
                ", ".join(data["fail_nodes"])))

def test_basic():
    """
    Run a single workload for a while.
    """
    global args
    log("Starting nodes")
    start_nodes(range(args.num_nodes))
    log("Starting servers")
    do_cmd("server --ports 4\n", range(args.num_nodes))
    log("Starting clients")
    do_cmd("client --threads 5 --server-ports 4 --workload %s --server-nodes 3 "
            "--first-server 0\n" % (args.workload),
            range(args.num_nodes))
    time.sleep(args.seconds)
    log("Dumping stats")
    do_cmd("dump_times rtts.txt\n", range(args.num_nodes))
    log("Retrieving stats")
    for n in range(args.num_nodes):
        subprocess.run(["rsync", "-rtvq", "node-%d:rtts.txt" % (n),
                "%s/rtts-%d.txt" % (args.log_dir, n)])

def test_slowdown():
    """
    Generate slowdown graphs for each of the workloads, comparing TCP and
    Homa.
    """

    global args
    r = range(args.num_nodes)
    try:
        log("Starting nodes")
        start_nodes(r)
        log_level = "normal"
        if args.verbose:
            log_level = "verbose"
        do_cmd("log --file node.log --level %s\n" % (log_level), r)

        log("Starting Homa servers")
        do_cmd("server --ports 9\n", r)

        log("Starting Homa clients (unloaded)")
        do_cmd("client --threads 1 --server-ports 1 --workload %s "
                "--server-nodes 1 --first-server 2 --thread-max 1\n" % (
                args.workload), [1])
        log("Starting unloaded experiment")
        do_cmd("dump_times /dev/null\n", r)
        do_cmd("log Starting unloaded experiment\n", r)
        time.sleep(args.seconds)
        log("Dumping unloaded stats")
        do_cmd("dump_times unloaded.txt\n", r)

        log("Restarting Homa clients (loaded)")
        do_cmd("stop clients\n", r)
        for node in r:
            command = "client --threads 5 --server-ports 9 --workload %s " \
                    "--server-nodes %d --first-server 0 --net-bw %.3f " \
                    "--thread-max %d --server-max %d --id %d\n" % (
                    args.workload, args.num_nodes, args.net_bw,
                    args.thread_max, args.server_max, node)
            nodes[node].stdin.write(command)
            nodes[node].stdin.flush()
        wait_output("% ", r, command)
        log("Starting loaded experiment")
        for node in r:
            subprocess.run(["rsh", "node-%d" % (node), "metrics.py"],
                    stdout=subprocess.DEVNULL)
        do_cmd("dump_times /dev/null\n", r)
        do_cmd("log Starting loaded experiment\n", r)
        time.sleep(args.seconds)
        log("Dumping loaded stats")
        do_cmd("dump_times loaded.txt\n", r)
        for node in r:
            f = open("%s/node-%d.metrics" % (args.log_dir, node), 'w')
            subprocess.run(["rsh", "node-%d" % (node), "metrics.py"], stdout=f);
            f.close()

        log("Restarting servers for TCP")
        do_cmd("stop clients\n", r)
        do_cmd("stop servers\n", r)
        do_cmd("server --ports 9  --protocol tcp\n", r)
        log("Starting TCP clients (loaded)")
        do_cmd("client --threads 5 --server-ports 9 --workload %s "
                "--server-nodes %d --first-server 0 --net-bw %.3f "
                "--protocol tcp --thread-max %d --server-max %d\n" %
                (args.workload, args.num_nodes, args.net_bw, args.thread_max,
                args.server_max), r)
        log("Starting TCP experiment")
        do_cmd("dump_times /dev/null\n", r)
        do_cmd("log Starting TCP experiment\n", r)
        time.sleep(args.seconds)
        log("Dumping TCP stats")
        do_cmd("dump_times tcp.txt\n", r)
        log("Finishing")
        do_cmd("stop clients\n", r)
        stop_nodes()
    except Exception as e:
        log(traceback.format_exc())

    log("Retrieving logs")
    subprocess.run(["rsync", "-rtvq", "node-1:unloaded.txt",
            "%s/unloaded.txt" % (args.log_dir)])
    for n in r:
        subprocess.run(["rsync", "-rtvq", "node-%d:node.log" % (n),
                "%s/node-%d.log" % (args.log_dir, n)])
        subprocess.run(["rsync", "-rtvq", "node-%d:loaded.txt" % (n),
                "%s/loaded-%d.txt" % (args.log_dir, n)])
        subprocess.run(["rsync", "-rtvq", "node-%d:tcp.txt" % (n),
                "%s/tcp-%d.txt" % (args.log_dir, n)])
    scan_logs()
    log("Finished: results are in %s" % (args.log_dir))

parser = argparse.ArgumentParser(description=
        'Run one or more Homa performance benchmarks on a cluster of nodes.  '
        'Each test argument names one test to run.  To understand how a '
        'particular test works, look at the code for the function '
        'test_<name>, where a <name> is the value typed on the command '
        'line. Not all of the options described below are used by all '
        'benchmarks.',
        usage='%(prog)s [options] test test ...')
parser.add_argument('-b', '--net-bw', type=float, dest='net_bw',
        metavar='B', default=0.0,
        help='generate a total of B GB/sec of bandwidth from each client '
        'machine (default: 0, which means run as fast as possible)')
parser.add_argument('-d', '--debug', dest='debug', action='store_true',
        help='pause after starting servers to enable debugging setup')
parser.add_argument('-l', '--log-dir', dest='log_dir',
        metavar='D', default="logs/" + time.strftime('%Y%m%d%H%M%S'),
        help='directory to use for logs and metrics')
parser.add_argument('-n', '--nodes', type=int, dest='num_nodes',
        required=True, metavar='N',
        help='total number of nodes to use in the cluster')
parser.add_argument('-p', '--protocol', dest='protocol',
        choices=['homa', 'tcp'], default="homa",
        help='transport protocol to use (default: homa)')
parser.add_argument('-s', '--seconds', type=int, dest='seconds',
        metavar='S', default=5,
        help='run each experiment for S seconds (default: 5 secs)')
parser.add_argument('--server-max', type=int, dest='server_max',
        metavar='count', default=20,
        help='maximum number of requests a single client thread can have '
        'outstanding to a single server port at a time (default: 20)')
parser.add_argument('--thread-max', type=int, dest='thread_max',
        metavar='count', default=20,
        help='maximum number of requests each client thread can have '
        'outstanding at a time (default: 20)')
parser.add_argument('-v', '--verbose', dest='verbose', action='store_true',
        help='enable verbose output in node logs')
parser.add_argument('-w', '--workload', dest='workload',
        metavar='W', default="w3",
        help='workload to use for benchmark (w1-w5 or number, default: w3)')

args, tests = parser.parse_known_args()
if len(tests) == 0:
    print("No tests specified; type 'cperf --help' for help")
    exit(1)
if tests[0] == "scan":
    scan_logs()
    exit(0)
if os.path.exists(args.log_dir):
    shutil.rmtree(args.log_dir)
os.makedirs(args.log_dir)
log_file = open("%s/cperf.log" % args.log_dir, "w")

for test in tests:
    log("Running test %s" % (test))
    eval("test_%s()" % (test))